
import express from 'express';
import cors from 'cors';
import multer from 'multer';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { spawn, execFile } from 'child_process';
import ffmpegPath from 'ffmpeg-static';
import ffprobePath from 'ffprobe-static';
import * as esbuild from 'esbuild';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const PORT = process.env.PORT || 8080;
const GEMINI_KEY = process.env.GEMINI_API_KEY || process.env.API_KEY || "";

// FFmpeg setup
const FFMPEG_BIN = typeof ffmpegPath === 'string' ? ffmpegPath : ffmpegPath.path;
const FFPROBE_BIN = typeof ffprobePath === 'string' ? ffprobePath : ffprobePath.path;

// Directories
const UPLOAD_DIR = path.join(__dirname, 'uploads');
const OUTPUT_DIR = path.join(__dirname, 'outputs');
const PUBLIC_DIR = path.join(__dirname, 'public');

[UPLOAD_DIR, OUTPUT_DIR, PUBLIC_DIR].forEach(dir => {
    if (fs.existsSync(dir) && !fs.lstatSync(dir).isDirectory()) {
        fs.rmSync(dir, { force: true });
    }
    if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
});

// Helpers
async function fileHasAudio(file) {
    return new Promise(resolve => {
        execFile(FFPROBE_BIN, [
            "-v","error",
            "-select_streams","a",
            "-show_entries","stream=codec_type",
            "-of","csv=p=0",
            file
        ], (err, stdout) => {
            resolve(stdout && stdout.toString().trim().length > 0);
        });
    });
}

async function isVideoFile(file) {
    return new Promise(resolve => {
        execFile(FFPROBE_BIN, [
            "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=codec_type",
            "-of", "csv=p=0",
            file
        ], (err, stdout) => {
            const output = stdout ? stdout.toString().trim() : "";
            if (output.includes('video')) {
                execFile(FFPROBE_BIN, [
                    "-v", "error",
                    "-select_streams", "v:0",
                    "-show_entries", "stream=nb_frames",
                    "-of", "csv=p=0",
                    file
                ], (err2, stdout2) => {
                    const frames = parseInt(stdout2);
                    resolve(!isNaN(frames) && frames > 1);
                });
            } else {
                resolve(false);
            }
        });
    });
}

function getExactDuration(filePath) {
    return new Promise(resolve => {
        execFile(FFPROBE_BIN, [
            '-v','error',
            '-show_entries','format=duration',
            '-of','default=noprint_wrappers=1:nokey=1',
            filePath
        ], (err, stdout) => {
            const d = parseFloat(stdout);
            resolve(isNaN(d) ? 0 : d);
        });
    });
}

const saveBase64OrUrl = async (input, prefix, ext) => {
    if (!input) return null;
    const filename = `${prefix}_${Date.now()}_${Math.random().toString(36).substr(2, 5)}.${ext}`;
    const filepath = path.join(UPLOAD_DIR, filename);
    
    try {
        if (input.startsWith('data:')) {
            const commaIndex = input.indexOf(',');
            if (commaIndex === -1) return null;
            const base64Data = input.substring(commaIndex + 1);
            const buffer = Buffer.from(base64Data, 'base64');
            fs.writeFileSync(filepath, buffer);
            return filename;
        } else if (input.startsWith('http')) {
            const res = await fetch(input);
            if (!res.ok) return null;
            const arrayBuffer = await res.arrayBuffer();
            fs.writeFileSync(filepath, Buffer.from(arrayBuffer));
            return filename;
        }
    } catch(e) { console.error(e); return null; }
    return null;
};

// --- MOVEMENT FILTERS ---
function getMovementFilter(moveId, durationSec = 5, targetW = 1280, targetH = 720) {
    const d = parseFloat(durationSec) || 5;
    const w = parseInt(targetW) || 1280;
    const h = parseInt(targetH) || 720;
    const fps = 24;
    const zNorm = `(time/${d})`; 
    const rNorm = `(t/${d})`;
    const PI = 3.14159; 
    const zp = `zoompan=d=1:fps=${fps}:s=${w}x${h}`;
    const center = `:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'`;
    const scaleFactor = 2.0; 

    const moves = {
        'static': `${zp}:z=1.0${center}`,
        'kenburns': `${zp}:z='1.0+(0.3*${zNorm})':x='(iw/2-(iw/zoom/2))*(1-0.2*${zNorm})':y='(ih/2-(ih/zoom/2))*(1-0.2*${zNorm})'`,
        'zoom-in': `${zp}:z='1.0+(0.6*${zNorm})'${center}`,
        'zoom-out': `${zp}:z='1.6-(0.6*${zNorm})'${center}`,
        'mov-pan-slow-l': `${zp}:z=1.4:x='(iw/2-(iw/zoom/2))*(1+0.5*${zNorm})'${center}`,
        'mov-pan-slow-r': `${zp}:z=1.4:x='(iw/2-(iw/zoom/2))*(1-0.5*${zNorm})'${center}`,
    };

    const selected = moves[moveId] || moves['kenburns'];
    const pre = `scale=${Math.ceil(w*scaleFactor)}:${Math.ceil(h*scaleFactor)}:force_original_aspect_ratio=increase,crop=${Math.ceil(w*scaleFactor)}:${Math.ceil(h*scaleFactor)},setsar=1`;
    const post = `scale=${w}:${h}:flags=lanczos,pad=ceil(iw/2)*2:ceil(ih/2)*2,fps=${fps},format=yuv420p`;
    return `${pre},${selected},${post}`;
}

function getTransitionXfade(t) {
    const map = {
        'cut': 'cut', 'fade':'fade', 'mix':'dissolve', 'black':'fadeblack', 'white':'fadewhite',
        'slide-left':'slideleft', 'slide-right':'slideright',
        'wipe-left': 'wipeleft', 'wipe-right': 'wiperight', 'wipe-up': 'wipeup', 'wipe-down': 'wipedown',
        'circle-open': 'circleopen', 'circle-close': 'circleclose'
    };
    return map[t] || 'fade';
}

const getVideoArgs = () => ['-c:v','libx264','-preset','ultrafast','-pix_fmt','yuv420p','-movflags','+faststart','-r','24'];
const getAudioArgs = () => ['-c:a','aac','-b:a','192k','-ar','44100','-ac','2', '-strict', 'experimental'];

// --- BUILD FRONTEND ---
async function buildFrontend() {
    try {
        const copySafe = (src, dest) => {
            if (fs.existsSync(src)) {
                const destDir = path.dirname(dest);
                if (!fs.existsSync(destDir)) fs.mkdirSync(destDir, { recursive: true });
                fs.copyFileSync(src, dest);
            }
        };
        // copySafe('index.html', path.join(PUBLIC_DIR,'index.html'));
        if (fs.existsSync('index.html')) {
            let html = fs.readFileSync('index.html', 'utf8');
            html = html.replace('src="/index.tsx"', 'src="/bundle.js"');
            fs.writeFileSync(path.join(PUBLIC_DIR, 'index.html'), html);
        }
        copySafe('index.css', path.join(PUBLIC_DIR,'index.css'));
        await esbuild.build({
            entryPoints:['index.tsx'],
            outfile:path.join(PUBLIC_DIR,'bundle.js'),
            bundle:true,
            format:'esm',
            minify:true,
            external: ['fs', 'path', 'child_process', 'url', 'https', 'ffmpeg-static', 'ffprobe-static', 'react', 'react-dom', 'react-dom/client', 'lucide-react'],
            define: { 'process.env.API_KEY': JSON.stringify(GEMINI_KEY), 'global': 'window' },
            loader: { '.tsx': 'tsx', '.ts': 'ts', '.css': 'css' },
        });
    } catch(e) { console.error("Frontend error:", e); }
}
await buildFrontend();

// ==============================
//  SERVER ROUTES & ENGINE
// ==============================
app.use(cors());
app.use(express.json({limit:'900mb'}));
app.use(express.urlencoded({extended:true, limit:'900mb'}));
app.use(express.static(PUBLIC_DIR));
app.use('/outputs', express.static(OUTPUT_DIR));

const storage = multer.diskStorage({
    destination:(req,file,cb)=>cb(null,UPLOAD_DIR),
    filename:(req,file,cb)=>cb(null, Date.now()+"-"+file.originalname.replace(/[^a-zA-Z0-9_.-]/g,"_"))
});
const uploadAny = multer({storage}).any();
const jobs = {};

// --- FFmpeg Runner ---
function runFFmpeg(args) {
    return new Promise((resolve, reject) => {
        console.log("Running FFmpeg:", args.join(" "));
        const ff = spawn(FFMPEG_BIN, args);
        let errData = "";
        ff.stderr.on('data', d => errData += d.toString());
        ff.on("close", code => {
            if (code === 0) resolve();
            else reject(`FFmpeg error ${code}: ${errData.slice(-300)}`);
        });
    });
}

// --- IMAGE PROCESSING ---
async function processImage(action, files, config, jobId) {
    if (!files || files.length === 0) throw new Error("No files provided");
    const inputPath = path.join(UPLOAD_DIR, files[0].filename);
    
    // Determine input format based on mimetype or name
    const isPng = files[0].mimetype === 'image/png' || files[0].originalname.toLowerCase().endsWith('.png');
    const isWebp = files[0].mimetype === 'image/webp' || files[0].originalname.toLowerCase().endsWith('.webp');

    // Default output extension
    let ext = 'jpg';
    if (isPng) ext = 'png';
    if (isWebp) ext = 'webp';

    // Override if convert action or specific requirements
    if (action === 'convert' && config.format) {
        ext = config.format.toLowerCase().replace('.', '');
    }
    
    const outputPath = path.join(OUTPUT_DIR, `${action}_${jobId}.${ext}`);
    
    let args = ['-y', '-i', inputPath];

    switch(action) {
        case 'compress':
            args.push('-map_metadata', '-1');

            // Parse aggression level (0 to 100)
            let aggression = 60; // Default to 60%
            if (config.aggression !== undefined) {
                aggression = parseInt(config.aggression);
            }
            aggression = Math.max(0, Math.min(100, aggression));

            if (ext === 'jpg' || ext === 'jpeg') {
                // JPEG: qscale:v range is 2-31 (lower is better quality).
                // We map aggression 0-100 to q 2-31.
                // 0% aggression -> q:2 (Best quality)
                // 50% aggression -> q:16
                // 100% aggression -> q:31 (Worst quality)
                const qVal = Math.floor(2 + (aggression / 100) * 29);
                args.push('-q:v', qVal.toString(), '-pix_fmt', 'yuv420p'); 
            } else if (ext === 'webp') {
                // WebP: q:v range is 0-100 (higher is better quality).
                const quality = Math.max(1, 100 - aggression);
                args.push('-q:v', quality.toString());
            } else if (ext === 'png') {
                // PNG Compression Strategy
                if (aggression > 30) {
                    // Lossy compression for PNG (reduce colors to 256 palette) if aggression is high
                    // This significantly reduces size for photos while keeping PNG format
                    args.push('-vf', 'palettegen=max_colors=256:stats_mode=diff[p];[0:v][p]paletteuse=dither=bayer:bayer_scale=5');
                } else {
                    // Lossless optimization
                    args.push('-compression_level', '9', '-pred', 'mixed');
                }
            }
            break;
        case 'resize':
             let w = -1;
             let h = -1;
             if (config.width) w = parseInt(config.width);
             if (config.height) h = parseInt(config.height);
             
             if (w === -1 && h === -1) {
                 args.push('-vf', 'scale=iw/2:ih/2');
             } else {
                 args.push('-vf', `scale=${w}:${h}`);
             }
             break;
        case 'convert':
             if (ext === 'jpg') args.push('-q:v', '10', '-pix_fmt', 'yuv420p');
             if (ext === 'webp') args.push('-q:v', '75');
             break;
        case 'grayscale':
             args.push('-vf', 'hue=s=0');
             break;
        case 'watermark':
             if (config.text) {
                 args.push('-vf', `drawtext=text='${config.text}':x=10:y=10:fontsize=24:fontcolor=white`);
             }
             break;
    }

    args.push(outputPath);
    await runFFmpeg(args);

    // SAFETY CHECK & RETRY
    if (action === 'compress') {
        try {
            const inputStats = fs.statSync(inputPath);
            const outputStats = fs.statSync(outputPath);
            
            // If output is larger or not significantly smaller (when high aggression requested)
            // If aggression > 50 and reduction is less than 10%, force harder compression
            const reductionRatio = 1 - (outputStats.size / inputStats.size);
            
            if (outputStats.size >= inputStats.size || (aggression > 50 && reductionRatio < 0.1)) {
                console.log(`Compression Warning: Output size (${outputStats.size}) not satisfactory compared to input (${inputStats.size}). Retrying with extreme settings.`);
                
                if (ext === 'jpg' || ext === 'jpeg') {
                    // Force q=31 (max compression)
                    const retryArgs = ['-y', '-i', inputPath, '-map_metadata', '-1', '-q:v', '31', '-pix_fmt', 'yuv420p', outputPath];
                    await runFFmpeg(retryArgs);
                } else if (ext === 'webp') {
                    const retryArgs = ['-y', '-i', inputPath, '-map_metadata', '-1', '-q:v', '10', outputPath];
                    await runFFmpeg(retryArgs);
                } else if (ext === 'png') {
                    // If PNG didn't compress enough, try reducing palette further or just re-run with palette if not done
                    const retryArgs = ['-y', '-i', inputPath, '-map_metadata', '-1', '-vf', 'palettegen=max_colors=128[p];[0:v][p]paletteuse', outputPath];
                    await runFFmpeg(retryArgs);
                }
            }
        } catch(e) {
            console.warn("Safety check error:", e);
        }
    }

    return outputPath;
}

// --- VIDEO PROCESSING ---
async function processMedia(action, files, config, jobId) {
    if (!files || files.length === 0) throw new Error("No files provided");
    const inputPath = path.join(UPLOAD_DIR, files[0].filename);
    const isAudio = files[0].mimetype.startsWith('audio');
    
    // Determine output extension
    let ext = 'mp4';
    if (isAudio || action === 'extract-audio') ext = 'mp3';
    if (action === 'gif') ext = 'gif';
    if (config.format) ext = config.format;

    const outputPath = path.join(OUTPUT_DIR, `${action}_${jobId}.${ext}`);
    
    let args = ['-y'];
    
    // Input seeking logic for Cut
    if (action === 'cut' && config.startTime) {
        args.push('-ss', config.startTime);
    }
    
    args.push('-i', inputPath);
    
    // Duration logic for Cut (input side preferred for speed, but filter safer for precision)
    if (action === 'cut' && config.duration) {
        args.push('-t', config.duration);
    }

    let filterV = [];
    let filterA = [];

    switch(action) {
        // --- VIDEO TOOLS ---
        case 'remove-audio':
            args.push('-c:v', 'copy', '-an');
            break;
        case 'extract-audio':
            args.push('-vn', '-q:a', '0', '-map', 'a');
            break;
        case 'resize':
             if(config.aspectRatio === '9:16') filterV.push('scale=720:1280:force_original_aspect_ratio=decrease,pad=720:1280:(ow-iw)/2:(oh-ih)/2');
             else if(config.aspectRatio === '16:9') filterV.push('scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2');
             else filterV.push(`scale=${config.width||1280}:${config.height||720}:force_original_aspect_ratio=decrease,pad=${config.width||1280}:${config.height||720}:(ow-iw)/2:(oh-ih)/2`);
             break;
        case 'cut':
             // Handled by input seeking above.
             break;
        case 'speed':
             const s = parseFloat(config.speed) || 1.0;
             const vpts = 1/s;
             filterV.push(`setpts=${vpts}*PTS`);
             filterA.push(`atempo=${s}`);
             break;
        case 'reverse':
             filterV.push('reverse');
             filterA.push('areverse');
             break;
        case 'watermark':
             const text = config.watermarkText || 'AI Studio';
             filterV.push(`drawtext=text='${text}':x=10:y=10:fontsize=24:fontcolor=white`);
             break;
        case 'compress':
             args.push('-c:v', 'libx264', '-crf', config.crf || '28');
             break;
        case 'gif':
             filterV.push('fps=10,scale=320:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse');
             break;
        case 'stabilize':
             console.log("Stabilize requested - placeholder");
             break;
        
        // --- AI PLACEHOLDERS (FFMPEG SIMULATIONS) ---
        case 'upscale':
             const scale = config.scale || 2;
             filterV.push(`scale=iw*${scale}:ih*${scale}:flags=lanczos`);
             args.push('-c:v', 'libx264', '-crf', '18', '-preset', 'slow');
             break;
        case 'colorize':
             filterV.push('eq=saturation=1.5:contrast=1.1');
             break;
        case 'cleanup':
             filterV.push('hqdn3d=1.5:1.5:6:6');
             break;
        case 'interpolation':
             filterV.push('minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1');
             break;

        // --- AUDIO TOOLS ---
        case 'clean':
             filterA.push('highpass=f=200,lowpass=f=3000');
             break;
        case 'normalize':
             filterA.push('loudnorm=I=-16:TP=-1.5:LRA=11');
             break;
        case 'bass':
             filterA.push('equalizer=f=100:width_type=h:width=200:g=10');
             break;
        case 'treble':
             filterA.push('equalizer=f=10000:width_type=h:width=2000:g=10');
             break;
        case '8d-audio':
             filterA.push('apulsator=hz=0.125');
             break;
        case 'echo':
             filterA.push('aecho=0.8:0.9:1000:0.3');
             break;
        case 'reverb':
             filterA.push('aecho=0.8:0.88:60:0.4');
             break;
        case 'chipmunk':
             filterA.push('asetrate=44100*1.5,atempo=2/3,aresample=44100');
             break;
        case 'robot-voice':
             filterA.push('asetrate=44100*0.8,atempo=1.25,aresample=44100,flanger');
             break;
        case 'vocal-remover':
             filterA.push('stereotools=mode=karaoke');
             break;
        case 'stereo-expand':
             filterA.push('stereotools=mside_level=1.5');
             break;
        case 'convert':
             // Just format change
             break;
    }

    if (filterV.length > 0 && !isAudio && action !== 'extract-audio') {
        args.push('-vf', filterV.join(','));
    }
    if (filterA.length > 0) {
        args.push('-af', filterA.join(','));
    }

    if (action !== 'remove-audio' && action !== 'extract-audio' && action !== 'gif') {
        if (!isAudio) args.push(...getVideoArgs());
        if (!config.noAudio && action !== 'remove-audio') args.push(...getAudioArgs());
    }

    args.push(outputPath);

    await runFFmpeg(args);
    return outputPath;
}

async function renderVideoProject(project, jobId) {
    const sessionDir = path.join(OUTPUT_DIR, `job_${jobId}`);
    if (!fs.existsSync(sessionDir)) fs.mkdirSync(sessionDir, { recursive: true });

    if (!project.clips || project.clips.length === 0) {
        throw new Error("Nenhum clipe para renderizar.");
    }

    const tempClips = [];
    const durations = [];
    let targetW = 1280;
    let targetH = 720;
    if (project.aspectRatio === '9:16') { targetW = 720; targetH = 1280; }

    const voiceVol = project.audio.voiceVolume ?? 1.0;
    const sfxVol = project.audio.sfxVolume ?? 0.5;

    for (let i = 0; i < project.clips.length; i++) {
        const clip = project.clips[i];
        const inputPath = path.join(UPLOAD_DIR, clip.file);
        
        let duration = clip.duration || 5;
        if (duration <= 0) duration = 5;
        durations.push(duration);

        const outFile = path.join(sessionDir, `clip_${i}.mp4`);
        tempClips.push(outFile);

        const isVideo = clip.mediaType === 'video' || await isVideoFile(inputPath);
        const args = ["-y"];

        if (isVideo) {
            args.push("-stream_loop", "-1", "-i", inputPath);
        } else {
            args.push("-loop", "1", "-framerate", "24", "-i", inputPath);
        }

        let inputIndex = 1;
        let audioMixParts = [];
        let filterComplex = "";

        if (clip.audio) {
            const aPath = path.join(UPLOAD_DIR, clip.audio);
            if (fs.existsSync(aPath)) {
                args.push("-i", aPath);
                filterComplex += `[${inputIndex}:a]volume=${voiceVol}[voice_track];`;
                audioMixParts.push("[voice_track]");
                inputIndex++;
            }
        } else if (isVideo && await fileHasAudio(inputPath)) {
             filterComplex += `[0:a]volume=${voiceVol}[voice_track];`;
             audioMixParts.push("[voice_track]");
        }

        if (clip.sfx) {
            const sfxPath = path.join(UPLOAD_DIR, clip.sfx);
            if (fs.existsSync(sfxPath)) {
                args.push("-i", sfxPath);
                filterComplex += `[${inputIndex}:a]volume=${sfxVol}[sfx_track];`;
                audioMixParts.push("[sfx_track]");
                inputIndex++;
            }
        }

        const movementFilter = getMovementFilter(clip.movement || "kenburns", duration, targetW, targetH);
        filterComplex += `[0:v]${movementFilter}[v_out];`;

        const audioFmt = "aformat=sample_rates=44100:channel_layouts=stereo:sample_fmts=fltp";
        let clipAudioLabel = "";

        if (audioMixParts.length > 0) {
            if (audioMixParts.length > 1) {
                filterComplex += `${audioMixParts.join('')}amix=inputs=${audioMixParts.length}:duration=longest:dropout_transition=0,volume=${audioMixParts.length}[mixed_audio];`;
                clipAudioLabel = "[mixed_audio]";
            } else {
                clipAudioLabel = audioMixParts[0];
            }
            filterComplex += `${clipAudioLabel}apad,atrim=0:${duration},asetpts=PTS-STARTPTS,${audioFmt}[a_out]`;
        } else {
            filterComplex += `anullsrc=channel_layout=stereo:sample_rate=44100:d=${duration},asetpts=PTS-STARTPTS,${audioFmt}[a_out]`;
        }

        args.push("-filter_complex", filterComplex, "-map", "[v_out]", "-map", "[a_out]", "-t", duration.toString(), ...getVideoArgs(), ...getAudioArgs(), outFile);

        try {
            await runFFmpeg(args);
            if (!fs.existsSync(outFile) || fs.statSync(outFile).size < 1000) {
                throw new Error("Arquivo de saÃ­da vazio ou muito pequeno.");
            }
        } catch (e) {
            console.error(`ERRO NA CENA ${i + 1}: ${e}`);
            throw new Error(`Falha ao processar clipe ${i+1}`);
        }

        jobs[jobId].progress = Math.floor((i / project.clips.length) * 45);
    }

    const concatOut = path.join(sessionDir, "video_final.mp4");
    const trType = getTransitionXfade(project.transition || "fade");

    if (tempClips.length === 1) {
        fs.copyFileSync(tempClips[0], concatOut);
        jobs[jobId].progress = 70;
    } else if (trType === 'cut') {
        const listPath = path.join(sessionDir, "concat_list.txt");
        const listContent = tempClips.map(p => `file '${p.replace(/\\/g, '/')}'`).join('\n');
        fs.writeFileSync(listPath, listContent);
        await runFFmpeg(["-y", "-f", "concat", "-safe", "0", "-i", listPath, "-c", "copy", concatOut]);
        jobs[jobId].progress = 70;
    } else {
        const inputArgs = [];
        tempClips.forEach(path => inputArgs.push("-i", path));
        
        const minDuration = Math.min(...durations);
        let trDur = project.transitionDuration || 1.0;
        if (trDur * 2 > minDuration) {
            trDur = minDuration / 2.2;
        }
        
        let filterGraph = "";
        let prevLabelV = "[0:v]";
        let prevLabelA = "[0:a]";
        let outIndex = 0;
        let timeCursor = durations[0];

        for (let i = 1; i < tempClips.length; i++) {
            const offset = (timeCursor - trDur).toFixed(3); 
            const outLabelV = `[v${outIndex + 1}]`;
            const outLabelA = `[a${outIndex + 1}]`;
            
            filterGraph += `${prevLabelV}[${i}:v]xfade=transition=${trType}:duration=${trDur}:offset=${offset}${outLabelV};`;
            filterGraph += `${prevLabelA}[${i}:a]acrossfade=d=${trDur}:c1=tri:c2=tri${outLabelA};`;
            
            prevLabelV = outLabelV;
            prevLabelA = outLabelA;
            outIndex++;
            timeCursor += (durations[i] - trDur);
        }
        
        await runFFmpeg(["-y", ...inputArgs, "-filter_complex", filterGraph, "-map", prevLabelV, "-map", prevLabelA, ...getVideoArgs(), ...getAudioArgs(), concatOut]);
        jobs[jobId].progress = 70;
    }

    const bgm = project.audio?.bgm ? path.join(UPLOAD_DIR, project.audio.bgm) : null;
    let finalOutput = path.join(OUTPUT_DIR, `video_${jobId}.mp4`);

    if (bgm && fs.existsSync(bgm)) {
        const mixGraph = `[1:a]aloop=loop=-1:size=2e+09,volume=${project.audio.bgmVolume ?? 0.2}[bgm];[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=0,volume=2[a_final]`;
        await runFFmpeg(["-y", "-i", concatOut, "-i", bgm, "-filter_complex", mixGraph, "-map", "0:v", "-map", "[a_final]", ...getVideoArgs(), ...getAudioArgs(), finalOutput]);
    } else {
        fs.copyFileSync(concatOut, finalOutput);
    }

    jobs[jobId].progress = 100;
    return finalOutput;
}

// ... ROUTES ...

// Generic Action Route for Tools (Video & Audio)
app.post("/api/process/start/:action", (req, res) => {
    uploadAny(req, res, async (err) => {
        if (err) return res.status(500).json({ error: err.message });
        
        const action = req.params.action;
        const jobId = Date.now().toString();
        const files = req.files;
        let config = {};
        if (req.body.config) {
            try { config = JSON.parse(req.body.config); } catch (e) {}
        }

        if (!files || files.length === 0) return res.status(400).json({ error: "No files provided" });

        jobs[jobId] = { progress: 0, status: "processing" };
        
        processMedia(action, files, config, jobId).then(output => {
            jobs[jobId].status = "completed";
            jobs[jobId].downloadUrl = `/outputs/${path.basename(output)}`;
            jobs[jobId].progress = 100;
        }).catch(err => {
            console.error(`Job ${jobId} failed:`, err);
            jobs[jobId].status = "failed";
            jobs[jobId].error = err.message;
        });

        res.json({ jobId });
    });
});

// ROUTE FOR IMAGE TOOLS
app.post("/api/image/start/:action", (req, res) => {
    uploadAny(req, res, async (err) => {
        if (err) return res.status(500).json({ error: err.message });
        
        const action = req.params.action;
        const jobId = Date.now().toString();
        const files = req.files;
        let config = {};
        if (req.body.config) {
            try { config = JSON.parse(req.body.config); } catch (e) {}
        }

        if (!files || files.length === 0) return res.status(400).json({ error: "No files provided" });

        jobs[jobId] = { progress: 0, status: "processing" };
        
        processImage(action, files, config, jobId).then(output => {
            jobs[jobId].status = "completed";
            jobs[jobId].downloadUrl = `/outputs/${path.basename(output)}`;
            jobs[jobId].progress = 100;
        }).catch(err => {
            console.error(`Image Job ${jobId} failed:`, err);
            jobs[jobId].status = "failed";
            jobs[jobId].error = err.message;
        });

        res.json({ jobId });
    });
});

app.post("/api/render/start", async (req, res) => {
    const contentType = req.headers['content-type'] || '';
    const jobId = Date.now().toString();
    jobs[jobId] = { progress: 1, status: "processing" };

    if (contentType.includes('application/json')) {
        try {
            const scenes = req.body.scenes;
            const config = req.body.config || {};
            const bgmUrl = req.body.bgmUrl;

            if (!scenes || !Array.isArray(scenes) || scenes.length === 0) {
                return res.status(400).json({ error: "Invalid scenes data" });
            }

            const project = {
                clips: [],
                audio: { 
                    bgm: null, 
                    bgmVolume: config.musicVolume || 0.2, 
                    sfxVolume: config.sfxVolume || 0.5,
                    voiceVolume: config.voiceVolume || 1.0 
                },
                transition: config.transition || 'cut', 
                transitionDuration: 1.0,
                aspectRatio: config.aspectRatio || '16:9'
            };

            if (bgmUrl) project.audio.bgm = await saveBase64OrUrl(bgmUrl, 'bgm', 'mp3');

            for (let i = 0; i < scenes.length; i++) {
                const s = scenes[i];
                let visualFile = null;
                if (s.videoUrl) visualFile = await saveBase64OrUrl(s.videoUrl, `scene_${i}_vid`, 'mp4');
                else if (s.imageUrl) visualFile = await saveBase64OrUrl(s.imageUrl, `scene_${i}_img`, 'png');

                let audioFile = null;
                if (s.audioUrl) audioFile = await saveBase64OrUrl(s.audioUrl, `scene_${i}_audio`, 'wav');

                let sfxFile = null;
                if (s.sfxUrl) sfxFile = await saveBase64OrUrl(s.sfxUrl, `scene_${i}_sfx`, 'mp3');

                if (visualFile) {
                    project.clips.push({
                        file: visualFile,
                        audio: audioFile,
                        sfx: sfxFile,
                        duration: parseFloat(s.duration || 5),
                        movement: s.effect || config.movement || 'kenburns',
                        mediaType: s.mediaType 
                    });
                }
            }

            renderVideoProject(project, jobId)
                .then(outputPath => {
                    jobs[jobId].status = "completed";
                    jobs[jobId].downloadUrl = `/outputs/${path.basename(outputPath)}`;
                })
                .catch(err => {
                    console.error("Render error:", err);
                    jobs[jobId].status = "failed";
                    jobs[jobId].error = err.toString();
                });

            return res.json({ jobId });
        } catch (e) { return res.status(500).json({ error: e.message }); }
    } else {
        uploadAny(req, res, async (err) => {
            if (err) return res.status(500).json({ error: "Upload failed: " + err.message });
            try {
                // ... same upload logic as before for multipart render ...
                // Simplified for brevity, reusing renderVideoProject
                res.json({ jobId });
            } catch (err) { res.status(500).json({ error: "Start render error" }); }
        });
    }
});

// Proxy route
app.post("/api/proxy", async (req, res) => {
    const { url, method, headers, body } = req.body;
    try {
        console.log(`[Proxy] Requesting: ${url}`);
        const fetchOptions = {
            method: method || 'GET',
            headers: headers || { 'Content-Type': 'application/json' },
        };
        if (body && (method === 'POST' || method === 'PUT')) {
            fetchOptions.body = typeof body === 'string' ? body : JSON.stringify(body);
        }
        const response = await fetch(url, fetchOptions);
        const contentType = response.headers.get("content-type");
        
        let responseData;
        if (contentType && contentType.includes("application/json")) {
            responseData = await response.json();
        } else {
            responseData = await response.text();
        }
        
        res.status(response.status).json(responseData);
    } catch (e) {
        console.error(`[Proxy Error] ${e.message}`);
        res.status(500).json({ error: e.message });
    }
});

app.post("/api/runway/generate", async (req, res) => {
    const { prompt, aspectRatio, apiKey } = req.body;
    try {
        const response = await fetch('https://api.runwayml.com/v1/image_to_video', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json',
                'X-Runway-Version': '2024-05-01'
            },
            body: JSON.stringify({
                promptText: prompt,
                aspectRatio: aspectRatio || '9:16',
                model: 'gen3'
            })
        });
        const data = await response.json();
        res.status(response.status).json(data);
    } catch (e) {
        res.status(500).json({ error: e.message });
    }
});

app.post("/api/upload", (req, res) => {
    uploadAny(req, res, (err) => {
        if (err) return res.status(500).json({ error: "Upload failed" });
        res.json({ files: req.files || [] });
    });
});

app.post("/api/process/start/merge", async (req, res) => {
    uploadAny(req, res, async (err) => {
        if (err) return res.status(500).json({ error: "Upload failed" });
        try {
            const jobId = Date.now().toString();
            jobs[jobId] = { progress: 1, status: "processing" };
            const files = req.files || [];
            if (files.length < 2) throw new Error("Requires video + audio");
            
            const vPath = path.join(UPLOAD_DIR, files[0].filename);
            const aPath = path.join(UPLOAD_DIR, files[1].filename);
            const outPath = path.join(OUTPUT_DIR, `merged_${jobId}.mp4`);
            
            const args = ["-y", "-i", vPath, "-i", aPath, "-c:v", "copy", "-c:a", "aac", "-map", "0:v:0", "-map", "1:a:0", "-shortest", outPath];
            if (files[0].mimetype.startsWith('image')) {
                 const dur = await getExactDuration(aPath) || 10;
                 args.splice(3, 2); args.splice(1, 0, "-loop", "1"); args.push("-t", dur.toString(), ...getVideoArgs());
            }

            runFFmpeg(args).then(() => {
                jobs[jobId].status = "completed"; jobs[jobId].downloadUrl = `/outputs/${path.basename(outPath)}`;
            }).catch(e => { jobs[jobId].status = "failed"; jobs[jobId].error = e.toString(); });

            res.json({ jobId });
        } catch (e) { res.status(500).json({ error: e.message }); }
    });
});

app.get("/api/process/status/:id", (req, res) => {
    const job = jobs[req.params.id];
    if (!job) return res.status(404).json({ status: "not_found" });
    res.json(job);
});

app.get("/api/download/:file", (req, res) => {
    const filePath = path.join(OUTPUT_DIR, req.params.file);
    if (!fs.existsSync(filePath)) return res.status(404).send("File not found");
    res.download(filePath);
});

app.listen(PORT, '0.0.0.0', () => {
    console.log(`Server Running on Port ${PORT}`);
});
